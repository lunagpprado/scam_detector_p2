{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c0a0e4-2849-4a79-9b32-ee42c82b5232",
   "metadata": {},
   "source": [
    "# Scam Detector: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904a70d-a2f8-40e9-a4f5-ad7e7edb9011",
   "metadata": {},
   "source": [
    "    This Jupyter Notebook will be used to run a Random Forest Algorithm to predict if a given email is a scam or a ham(a normal email)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158aa78-4c8c-45f5-af34-15071349526a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3bf4d050-2499-4995-820a-c0d13d2f1a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import the packages we need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score # Used for accuracy calculation\n",
    "from sklearn.decomposition import TruncatedSVD # Used for dimensionality reduction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Used for text numerical vectorization\n",
    "from sklearn.model_selection import train_test_split # Used for randomly splitting between training and validation data\n",
    "from sklearn.preprocessing import StandardScaler # Used for standardizing vector distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc74f965-4e22-40d8-a5e8-8dbefe0a056e",
   "metadata": {},
   "source": [
    "## Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "86056790-d9a7-4865-8a6b-d8441a8ff176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_names = ['sender', 'receiver', 'subject', 'body', 'label', 'urls']\n",
    "path = \"./data/CEAS_08.csv\"\n",
    "data1 = pd.read_csv(path)\n",
    "data1 = data1.drop('date', axis=1) # Data wouldn't affect whether something is a scam or not\n",
    "col_names[-1], col_names[-2] = col_names[-2], col_names[-1]\n",
    "data1 = data1[col_names]\n",
    "data1.head(10)\n",
    "counts = data1['urls'].value_counts() # Used for checking how even different features are represented in the data.\n",
    "#print(counts)\n",
    "#data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8b6074f5-d961-41df-b5f8-a12ddfebbbfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1 = data1.drop('receiver', axis=1) # Reciever wouldn't affect whether something is a scam or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "5e7680ee-c303-4f85-b6f1-7b1011b2c074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data1\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "3744f921-3dd6-4470-b6f0-297abe8eead9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processes all na values with Empty strings\n",
    "data['sender'].fillna(' ', inplace=True)\n",
    "data['subject'].fillna(' ', inplace=True)\n",
    "data['body'].fillna(' ', inplace=True)\n",
    "\n",
    "#data['sender'].isnull().any() # used to check if any nulls remain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b518ff4f-2487-44fa-9720-31842708c019",
   "metadata": {},
   "source": [
    "## TF-IDF and Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8da1b45b-247f-4ab1-b816-0862b4d2ddbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49703,)\n",
      "(39154, 49703)\n"
     ]
    }
   ],
   "source": [
    "# Text Vectorization for numeric representation of the text data\n",
    "corpus_sender = data['sender'][0:]\n",
    "vectorizer_send = TfidfVectorizer()\n",
    "send = vectorizer_send.fit_transform(corpus_sender)\n",
    "print(vectorizer_send.get_feature_names_out().shape)\n",
    "print(send.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "8855a81d-74f7-4445-8bc6-86157e44c17e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_send = TruncatedSVD(n_components=5, random_state=42) # Performs SVD to reduce the dimensionality of the vectors into something usable.\n",
    "send_reduced = svd_send.fit_transform(send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "df9dbbe9-4b65-4400-a97b-88bbcc773bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15339,)\n",
      "(39154, 15339)\n"
     ]
    }
   ],
   "source": [
    "# Text Vectorization for numeric interpretations\n",
    "corpus_sub = data['subject'][0:]\n",
    "vectorizer_sub = TfidfVectorizer()\n",
    "sub = vectorizer_sub.fit_transform(corpus_sub)\n",
    "print(vectorizer_sub.get_feature_names_out().shape)\n",
    "print(sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "d0a27fe5-68eb-48fb-b362-2901b3b74568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd_sub = TruncatedSVD(n_components=50, random_state=42)\n",
    "sub_reduced = svd_sub.fit_transform(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "84ca49bb-0533-448b-8166-f6c44f80e8de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183381,)\n",
      "(39154, 183381)\n"
     ]
    }
   ],
   "source": [
    "# Text Vectorization for numeric interpretations\n",
    "corpus_body = data['body'][0:]\n",
    "vectorizer_body = TfidfVectorizer()\n",
    "body = vectorizer_body.fit_transform(corpus_body)\n",
    "print(vectorizer_body.get_feature_names_out().shape)\n",
    "print(body.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6584d65b-8b8f-4c0c-8cf0-70dffd76121f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=300, random_state=42) \n",
    "body_reduced = svd.fit_transform(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "df2139ea-0d10-4d79-9302-7a630c975ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dupes_data = data.index[data.index.duplicated()] # Checks for duplicate rows\n",
    "#print(\"data duplicates:\", dupes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "27858db0-7f21-4d87-b2be-6c6ee50ed53f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler_body = StandardScaler() # Performs a standard scaler z=(x-mu)/sigma, in order to get it to a mean of 0 and variance of 1 for easier algorithmic analysis\n",
    "body_reduced = scaler_body.fit_transform(body_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "4440848b-b36c-4f3c-b51c-04fd8e6c8b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler_send = StandardScaler()\n",
    "send_reduced = scaler_send.fit_transform(send_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "3369909e-1792-48c5-a72c-eb3b3c0a1958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler_sub = StandardScaler()\n",
    "sub_reduced = scaler_sub.fit_transform(sub_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "bdc7eff7-b796-43e1-894a-a264147e0217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body_df = pd.DataFrame(body_reduced, columns=range(1,301))\n",
    "send_df = pd.DataFrame(send_reduced, columns=range(1,6))\n",
    "sub_df = pd.DataFrame(sub_reduced, columns=range(1,51))\n",
    "\n",
    "new_data = pd.concat([body_df, send_df, sub_df, data], axis=1)\n",
    "new_data = new_data.drop('body', axis=1)\n",
    "new_data = new_data.drop('sender', axis=1)\n",
    "new_data = new_data.drop('subject', axis=1)\n",
    "#new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "a146c66d-f833-4baf-9491-7f850c9ca2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d03f89fd-7b81-4b8c-8621-c54fdac8079b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3dd24-2d2c-44b9-ac8b-a19d2a9274ae",
   "metadata": {},
   "source": [
    "## Decision Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "51a30e7b-9f5b-499f-a970-a6a90897f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision:\n",
    "    \"\"\" A decision is used to ask the question at a decision node to split the data.\n",
    "    This class records column number and values and matches the stored feature value to a give feature value\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_index, threshold):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def ask(self, input):\n",
    "        # Compares input feature value to stored value\n",
    "        feature_val = input[self.feature_index]\n",
    "        if isinstance(feature_val, (int, float, np.number)):\n",
    "            return feature_val >= self.threshold\n",
    "        else:\n",
    "            return feature_val == self.threshold\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f4395-283e-4086-8403-750c64cec056",
   "metadata": {},
   "source": [
    "## Helper Functions for Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9260ee4a-d7cb-4af6-b999-0c8d978b1d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def divide_df(rows, decision):\n",
    "    # Partitions a data frame\n",
    "    # Check if each row matches decision, divide into true and false\n",
    "    col = rows[:, decision.feature_index]\n",
    "    if np.issubdtype(col.dtype, np.number):\n",
    "        mask = col >= decision.threshold\n",
    "    else:\n",
    "        mask = col == decision.threshold\n",
    "    left, right = rows[mask],rows[~mask]\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b3e2dac2-d911-476c-9829-a32d714e81ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_count(rows):\n",
    "    # Counts the number of each classification in data frame\n",
    "    y = rows[:, -1]\n",
    "    unique, label_counts = np.unique(y, return_counts=True)\n",
    "    return dict(zip(unique,label_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "fac30633-31c2-4bbb-ac1c-3fb62889c962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gini_impurity(rows):\n",
    "    #Calculates Gini Impurity for a data frame of rows.\n",
    "    y = rows[:, -1]\n",
    "    _, label_counts = np.unique(y, return_counts=True)\n",
    "    probs = label_counts/label_counts.sum()\n",
    "    return 1.0 - np.sum(probs**2) # gini impurity formula of a data frame based on label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "2c7863f0-afc2-447b-8931-5a1da1aa6cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def info_gain(left, right, curr_gini):\n",
    "    #Information gain: Gini of the root node subtracted by the impurty of the two children nodes.\n",
    "    if len(left) + len(right) == 0:\n",
    "        return 0\n",
    "    prob = float(len(left) / (len(left) + len(right)))\n",
    "    return curr_gini - prob * gini_impurity(left) - (1 - prob) * gini_impurity(right) #Information gain formula\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "e31f6718-279d-41aa-8c51-a3fac04e2db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def threshold_candidates(col, max_thresh=5):\n",
    "    #Choose candidate threshold split\n",
    "    unique = np.unique(col)\n",
    "    if len(unique) > max_thresh:\n",
    "        quantile = np.linspace(0, 100, max_thresh + 2)[1:-1]\n",
    "        unique = np.percentile(unique, quantile)\n",
    "    if len(unique) > 1:\n",
    "        return (unique[:-1] + unique[1:])/2\n",
    "    else:\n",
    "        return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "a0f701e0-7ce2-49eb-b193-147a2d75344e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def info_gain_split(rows):\n",
    "    #Find best decision to make based on informaiton gain\n",
    "    X = rows[:, :-1]\n",
    "    y = rows[:, -1]\n",
    "    curr_gini = gini_impurity(rows)\n",
    "    feature_count = X.shape[1]\n",
    "    \n",
    "    highest_gain = 0\n",
    "    optimal_decision = None\n",
    "    \n",
    "    for feature_index in range(feature_count):\n",
    "        col = X[:, feature_index]\n",
    "        \n",
    "        #Candidate Thresholds\n",
    "        thresholds = threshold_candidates(col) if np.issubdtype(col.dtype, np.number) else np.unique(col)\n",
    "        \n",
    "        for candidate in thresholds:\n",
    "            if np.issubdtype(col.dtype, np.number):\n",
    "                mask = col >= candidate #Mask is a true/false matrix which then gets the rows divide based on threshold\n",
    "            else:\n",
    "                mask = col == candidate\n",
    "            \n",
    "            if mask.sum() == 0 or mask.sum() == len(mask):\n",
    "                continue\n",
    "        \n",
    "            left, right = rows[mask], rows[~mask]\n",
    "            gain = info_gain(left, right, curr_gini)\n",
    "            \n",
    "            if gain > highest_gain:\n",
    "                highest_gain, optimal_decision = gain, Decision(feature_index, candidate)\n",
    "                \n",
    "    return highest_gain, optimal_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e97671-bb4e-4938-acb7-26e7ef9fa6cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Tree and Node Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "27e43030-1837-4a29-9654-ddf88ceed02c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    # A leaf Node holdes classified data.\n",
    "    # Holds a dictionary with class counts in the leaf.\n",
    "    \n",
    "    def __init__(self,rows):\n",
    "        self.pred = label_count(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "87efda5b-d2c1-41fa-86bc-94824b7d985f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    # A Decision Node asks a Decision to be made.\n",
    "    # Holds reference to a Decision, and two child nodes.\n",
    "    \n",
    "    def __init__(self, decision, left, right):\n",
    "        self.decision = decision\n",
    "        self.left = left\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ec9b89fa-2962-4318-8737-3da67ef0c922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_tree(rows, depth=0, max_depth=10, min_sample_split=2):\n",
    "    # Recursively Builds tree. Fitting at the same time.\n",
    "    if len(rows) < min_sample_split or depth >= max_depth:\n",
    "        return LeafNode(rows)\n",
    "    \n",
    "    highest_gain, optimal_decision = info_gain_split(rows)\n",
    "    \n",
    "    #Base case no further gain\n",
    "    if highest_gain < 1e-6 or optimal_decision is None:\n",
    "        return LeafNode(rows)\n",
    "    \n",
    "    #Found Partition\n",
    "    left, right = divide_df(rows, optimal_decision)\n",
    "    \n",
    "    #Recurse Left Subtree\n",
    "    left_subtree = build_tree(left, depth+1, max_depth, min_sample_split)\n",
    "    \n",
    "    #Recurse Right Subtree\n",
    "    right_subtree = build_tree(right, depth+1, max_depth, min_sample_split)\n",
    "    \n",
    "    #Return Decision Node\n",
    "    return DecisionNode(optimal_decision, left_subtree, right_subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2f988394-3178-469b-bc9c-853ea393676b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(row, curr_node):\n",
    "    #Base Case: Curr node is a leaf\n",
    "    if isinstance(curr_node, LeafNode):\n",
    "        total = sum(curr_node.pred.values())\n",
    "        return max(curr_node.pred, key=curr_node.pred.get), {k: v/total for k,v in curr_node.pred.items()}\n",
    "    \n",
    "    #Recurse the left or right subtree\n",
    "    if curr_node.decision.ask(row):\n",
    "        return predict(row, curr_node.left)\n",
    "    else:\n",
    "        return predict(row, curr_node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca4e1a-a2b8-488c-a79a-cb47f62bcff4",
   "metadata": {},
   "source": [
    "## Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "03f31358-ba36-4e72-ab13-88cae74d9c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, tree_count=10, max_depth=10, min_sample_split=2, feature_count=None):\n",
    "        self.tree_count = tree_count # number of trees in forest\n",
    "        self.max_depth = max_depth # maximum depth(height) of each tree\n",
    "        self.min_sample_split = min_sample_split # minimum sample split at each decision node\n",
    "        self.feature_count = feature_count # number of features within the dataset\n",
    "        self.trees = [] # list of tree pointers\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        self.feature_count = X.shape[1]\n",
    "        self.feature_subspaces = [] # feature subsets of each tree \n",
    "        \n",
    "        for _ in range(self.tree_count):\n",
    "            X_partial, y_partial = self.bootstrap(X, y) # selects a subset of data points\n",
    "            feature_index = np.random.choice(self.feature_count, int(np.sqrt(self.feature_count)), replace=False) # selects a sqrt number of features to be used in each tree\n",
    "            self.feature_subspaces.append(feature_index)\n",
    "            X_subspace = X_partial[:, feature_index] # indexes the feature subset\n",
    "            rows = np.concatenate((X_subspace, y_partial), axis=1)\n",
    "            \n",
    "            tree = build_tree(rows, max_depth=self.max_depth, min_sample_split=self.min_sample_split) # builds each subsetted tree\n",
    "            self.trees.append(tree)\n",
    "        \n",
    "        \n",
    "    def bootstrap(self, X, y):\n",
    "        # Selects a random sample of the data points for a tree\n",
    "        sample_count = X.shape[0]\n",
    "        row_index = np.random.choice(sample_count, sample_count, replace=True)\n",
    "        return X[row_index], y[row_index]\n",
    "        \n",
    "    \n",
    "    def subspace(self, X):\n",
    "        # selects a random sample of features for a tree\n",
    "        feature_index = np.random.choice(self.feature_count, int(self.feature_count**0.5), replace=False)\n",
    "        return X[:, feature_index]\n",
    "       \n",
    "                                  \n",
    "    def predict_one(self, X):\n",
    "        # Returns one prediction from the trees based on a new input X\n",
    "        votes = []\n",
    "        vector = []\n",
    "        for tree, features in zip(self.trees, self.feature_subspaces):\n",
    "            X_subspace = X[features]\n",
    "            pred, _  = predict(X_subspace, tree)\n",
    "            vector.append(pred)\n",
    "            votes.append(pred)\n",
    "        return max(set(votes), key=votes.count), vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4af2b-571d-4db2-b9e7-4ac2a5c003b2",
   "metadata": {},
   "source": [
    "## Prediction and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "87b1e746-7fd1-4277-9ca9-e24e12700ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rf_predict(forest, sender, subject, body, url=0):\n",
    "    input_data = {'sender': [sender], 'subject': [subject], 'body':[body], 'urls':[url]}\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    \n",
    "    input_body = vectorizer_body.transform(input_df['body'])\n",
    "    input_body_reduced = svd.transform(input_body)\n",
    "    input_body_reduced = scaler_body.transform(input_body_reduced)\n",
    "    input_body_df = pd.DataFrame(input_body_reduced, columns=range(1,301))\n",
    "\n",
    "    input_send = vectorizer_send.transform(input_df['sender'])\n",
    "    input_send_reduced = svd_send.transform(input_send)\n",
    "    input_send_reduced = scaler_send.transform(input_send_reduced)\n",
    "    input_send_df = pd.DataFrame(input_send_reduced, columns=range(1,6))\n",
    "\n",
    "    input_sub = vectorizer_sub.transform(input_df['subject'])\n",
    "    input_sub_reduced = svd_sub.transform(input_sub)\n",
    "    input_sub_reduced = scaler_sub.transform(input_sub_reduced)\n",
    "    input_sub_df = pd.DataFrame(input_sub_reduced, columns=range(1,51))\n",
    "    \n",
    "\n",
    "    input_data = pd.concat([input_body_df, input_send_df, input_sub_df, input_df], axis=1)\n",
    "    input_data = input_data.drop('body', axis=1)\n",
    "    input_data = input_data.drop('subject', axis=1)\n",
    "    input_data = input_data.drop('sender', axis=1)\n",
    "    \n",
    "    input_df = input_data\n",
    "    \n",
    "    input_x = input_df.to_numpy()[0,:]\n",
    "    pred, votes = my_forest.predict_one(input_x)\n",
    "    return pred, votes.count(prediction)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0feed11d-3ed0-4eb8-b2a6-16a9e9ceaf8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.to_numpy()[:,:-1]\n",
    "y = data.to_numpy()[:, -1].reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "b8c6eafc-2ca8-4d4a-8ec5-5cb60cc412f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_forest = RandomForest(tree_count=10, max_depth=10, min_sample_split=2, feature_count=X_train.shape[1])\n",
    "my_forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "32e783d8-cd32-4b60-9f50-058d88cd88b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array([my_forest.predict_one(X)[0] for X in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7165bade-c207-4b22-b150-5614f64b33cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9572212999616907\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, arr)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "ca0b6e0f-5710-4759-b1d8-e8d476b16ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Example Normal Email:\n",
    "#test_data = {'sender': ['luna_prado@gmail.com'], 'subject': ['Advisor Help'], 'body':['Hello Dr. Athienitis, can you help me with choosing classes for the upcoming semester. Look forward to staying in contact.'], 'urls':[0]}\n",
    "#test_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "5d2b5c17-5fb8-45f1-a168-a3e2c2ef3540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Example Scam Email:\n",
    "#test_data = {'sender': ['amazon.asjfnakjsnfkanf@gmail.com'], 'subject': ['SCAM URGENT'], 'body':['Make money quick, urgent new opportunity. Please buy now for your future. Passive Income, Easy life. Venmo.com. Akjfaksjnkasfjna.com'], 'urls':[1]}\n",
    "#test_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "9f088fda-9060-4206-95ec-7e1ac484b429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email is a Scam!\n",
      "Probability of Scam: 80.0 %\n"
     ]
    }
   ],
   "source": [
    "prediction, prob = rf_predict(my_forest, sender='amazon.asjfnakjsnfkanf@gmail.com', subject='SCAM URGENT', body='Make money quick, urgent new opportunity. Please buy now for your future. Passive Income, Easy life. Venmo.com. Akjfaksjnkasfjna.com', url=0)\n",
    "if prediction == 1.0:\n",
    "    print(\"The email is a Scam!\")\n",
    "elif prediction == 0.0:\n",
    "    print(\"The email is not a Scam!\")\n",
    "    \n",
    "print('Probability of Scam:', prob*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eea4eb-ed3b-49e6-8263-34d74fedc1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
